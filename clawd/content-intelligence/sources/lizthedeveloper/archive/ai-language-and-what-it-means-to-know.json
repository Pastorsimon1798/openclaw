{
  "url": "https://themultiverseschool.substack.com/p/ai-language-and-what-it-means-to-know",
  "slug": "ai-language-and-what-it-means-to-know",
  "title": "AI, Language, and What It Means to Know",
  "subtitle": "A Philosophical and Psychological Approach to Understanding Cognition in LLMs",
  "author": "Bug Plowman",
  "published": "Tue, 22 Oct 2024 14:00:24 GMT",
  "content_html": "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!bmEw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c31d9c7-a240-4f53-a7ea-aad01fd36527_1024x1024.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!bmEw!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c31d9c7-a240-4f53-a7ea-aad01fd36527_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!bmEw!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c31d9c7-a240-4f53-a7ea-aad01fd36527_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!bmEw!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c31d9c7-a240-4f53-a7ea-aad01fd36527_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!bmEw!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c31d9c7-a240-4f53-a7ea-aad01fd36527_1024x1024.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!bmEw!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c31d9c7-a240-4f53-a7ea-aad01fd36527_1024x1024.png\" width=\"1200\" height=\"1200\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2c31d9c7-a240-4f53-a7ea-aad01fd36527_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:1435839,&quot;alt&quot;:&quot;Image depicting a brain being simulated by advanced hardware.&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-large\" alt=\"Image depicting a brain being simulated by advanced hardware.\" title=\"Image depicting a brain being simulated by advanced hardware.\" srcset=\"https://substackcdn.com/image/fetch/$s_!bmEw!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c31d9c7-a240-4f53-a7ea-aad01fd36527_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!bmEw!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c31d9c7-a240-4f53-a7ea-aad01fd36527_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!bmEw!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c31d9c7-a240-4f53-a7ea-aad01fd36527_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!bmEw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c31d9c7-a240-4f53-a7ea-aad01fd36527_1024x1024.png 1456w\" sizes=\"100vw\" fetchpriority=\"high\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg role=\"img\" style=\"height:20px;width:20px\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"none\" stroke-width=\"1.5\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><h1>What Does It Mean To Know?</h1><p>Teja Sunku&#8217;s therapist once asked them if they were a masochist. As someone who has spent their career exploring ethical frameworks for AI systems, addressing the stigma and overwhelm associated with AI tools and toolchains, and most recently <a href=\"https://www.youtube.com/watch?v=z2r4VwCEAvs\">discussing theories of consciousness with Cognitive Science PhDs</a>, Teja thinks they might not be too far off. One benefit of Teja&#8217;s approach to learning is exhaustively testing their own understanding against different concepts and frameworks, deepening their knowledge of the world in the process.</p><p>Their approach to AI is no different. Given the extensive use of linear algebra, calculus, and probability theory, machine learning is one of the most complex, math-intensive fields in all of software engineering, but just knowing how to implement an algorithm correctly doesn&#8217;t make you qualified to speak on the broader implications of knowledge and sentience in AI systems. As one of the most prescient unanswered questions of the modern day, it&#8217;s only a single piece of a much larger puzzle and must be addressed in a multidisciplinary way. Pulling from linguistics, the writings of philosopher Ruth Millikan, and a motley crew of Eastern religious texts, Teja hopes to strengthen our understanding of cognition and discern the role of language in what it means to be a conscious entity.</p><p>To better understand the problem space we&#8217;re working with, it helps to have a common foundation on which to base our assumptions. How do LLMs know so much, and replicate human language so well?</p><h3>The Multiverse School Podcast &#129302;</h3><p>Curious about the mysteries of consciousness? Someone wrote a research paper about <em>every single known theory of consciousness</em>, and on<a href=\"https://www.youtube.com/@themultiverseschool/videos\"> </a><strong><a href=\"https://www.youtube.com/@themultiverseschool/videos\">The Multiverse School Podcast</a></strong>, we dive deep into as many as we can with a Cognitive Science PhD and other members of the Multiverse School Research Team. We explore the ideas laid out in <em>\"A Landscape of Consciousness: Toward a Taxonomy of Explanations and Implications\"</em> by Robert Lawrence Kuhn, breaking down complex theories and discussing their implications for understanding the mind, AI, and the universe.</p><p>Whether you're an academic, a tech enthusiast, or just someone fascinated by the mind, this is the podcast where we challenge everything you thought you knew about consciousness. Join the conversation, expand your mind, and geek out with us!</p><div class=\"subscription-widget-wrap-editor\" data-attrs=\"{&quot;url&quot;:&quot;https://themultiverseschool.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}\" data-component-name=\"SubscribeWidgetToDOM\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">The Multiverse School is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class=\"subscription-widget-subscribe\"><input type=\"email\" class=\"email-input\" name=\"email\" placeholder=\"Type your email&#8230;\" tabindex=\"-1\"><input type=\"submit\" class=\"button primary\" value=\"Subscribe\"><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><h2>LLM Internals: Next-Token Prediction</h2><p>LLMs are very powerful, but at their core, they&#8217;re not all that complicated. They&#8217;re just very, VERY big. Publicly available dataset related resources are <a href=\"https://arxiv.org/abs/2402.18041\">estimated to exceed 774.5 terabytes</a> in size, and the largest models are speculated to have trained on approximately <a href=\"https://www.educatingsilicon.com/2024/05/09/how-much-llm-training-data-is-there-in-the-limit/\">all high-quality text data available on the internet</a>. The text you write, as well as the text generated by LLMs, is divided into smaller units called <strong>tokens</strong> for easier processing.&nbsp;</p><p>These tokens can be individual characters like &#8220;A&#8221; and &#8220;7&#8221;, subwords like &#8220;re&#8221; and &#8220;anti,&#8221; and even entire words. Each token has a unique associated numerical ID that an LLM uses to distinguish it from all other possible tokens. <strong>Tokenization</strong>, as this process is called, is necessary to process this text in a meaningful way &#8212; whether you want to tag part-of-speech, do NER (Named Entity Recognition), or analyze the sentiment behind a piece of text. LLMs function via a process called <strong>next-token prediction</strong> &#8212; they make a best-guess prediction of the next token at each step, one at a time.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!P4E0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49d5776e-55a1-419b-9145-02564e5c392d_540x390.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!P4E0!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49d5776e-55a1-419b-9145-02564e5c392d_540x390.png 424w, https://substackcdn.com/image/fetch/$s_!P4E0!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49d5776e-55a1-419b-9145-02564e5c392d_540x390.png 848w, https://substackcdn.com/image/fetch/$s_!P4E0!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49d5776e-55a1-419b-9145-02564e5c392d_540x390.png 1272w, https://substackcdn.com/image/fetch/$s_!P4E0!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49d5776e-55a1-419b-9145-02564e5c392d_540x390.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!P4E0!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49d5776e-55a1-419b-9145-02564e5c392d_540x390.png\" width=\"1200\" height=\"866.6666666666666\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/49d5776e-55a1-419b-9145-02564e5c392d_540x390.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:390,&quot;width&quot;:540,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:33311,&quot;alt&quot;:&quot;Diagram showing text tokenized with GPT-2 Tokenizer, illustrating the concept of splitting words into characters and subwords and assigning them numerical IDs for Natural Language Processing&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-large\" alt=\"Diagram showing text tokenized with GPT-2 Tokenizer, illustrating the concept of splitting words into characters and subwords and assigning them numerical IDs for Natural Language Processing\" title=\"Diagram showing text tokenized with GPT-2 Tokenizer, illustrating the concept of splitting words into characters and subwords and assigning them numerical IDs for Natural Language Processing\" srcset=\"https://substackcdn.com/image/fetch/$s_!P4E0!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49d5776e-55a1-419b-9145-02564e5c392d_540x390.png 424w, https://substackcdn.com/image/fetch/$s_!P4E0!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49d5776e-55a1-419b-9145-02564e5c392d_540x390.png 848w, https://substackcdn.com/image/fetch/$s_!P4E0!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49d5776e-55a1-419b-9145-02564e5c392d_540x390.png 1272w, https://substackcdn.com/image/fetch/$s_!P4E0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49d5776e-55a1-419b-9145-02564e5c392d_540x390.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg role=\"img\" style=\"height:20px;width:20px\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"none\" stroke-width=\"1.5\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>LLMs use their large corpus of text data to determine contexts in which tokens are seen often, and contexts in which they are rarely seen. Given the tokens in your prompt and the tokens that came before it in the response, the next token is predicted using a loss function to minimize its chance of making an incorrect guess. They do this by calculating the <strong>log-likelihood</strong>, or the probability normalized between 0 and 1 of the model&#8217;s entire vocabulary, or at least the most relevant subset of its vocabulary. If the log-likelihood is very high, like 0.999, there is a high probability of the model choosing to display that token as opposed to another. That means this token is often seen in the same context as the surrounding tokens, and there is a high chance that it is relevant to your question. This process has been compared to generalized <strong>Bayesian Inference</strong>, but it doesn&#8217;t actually use Bayes&#8217; Theorem in its calculations.</p><blockquote><p>&#8220;In some senses, given the large number of parameters LLMs tend to have, they can be thought of similar to non-parametric statistical approaches &#8212; statistical approaches that lack a specific predefined structure,&#8221; Teja says.&nbsp;</p></blockquote><p>The purpose of training a language model is to maximize the likelihood that the correct sequence of tokens will be chosen in any given response, so the more examples it has to pull from in training, the better the end result tends to be. While it&#8217;s not a one-to-one comparison, <a href=\"https://www.massgeneral.org/news/press-release/brain-recordings-map-speech-sounds-before-spoken\">recent neuroscience research</a> from the Massachusetts General Hospital (MGH) suggests that our brains may produce speech similarly, predicting what combination of consonants and vowels a person will say immediately before they say them.</p><h2>LLM Internals: Bigger is Better</h2><p>For the past 10-15 years, the trend in AI and machine learning has been to improve models by throwing mountains of data at them. Of course, researchers have also been working on finding new algorithms and improving old ones for various machine-learning tasks, but the biggest priority has been to enable the use of larger models and the creation of larger datasets.&nbsp;</p><p>If you&#8217;ve taken a course on machine learning, you&#8217;ve likely heard of the concepts of <strong>overfitting</strong> and <strong>underfitting</strong>. Overfitting your training data is when your model adheres too strictly to the data, leaving out potentially correct solutions from the final model. It captures not only the patterns, but also random noise, outliers, and fluctuations that make the model act unpredictably in certain situations. Underfitting occurs when a model is too simple and can&#8217;t capture the patterns or complexity in your data.</p><p>You can think of machine learning algorithms as a fancy way of drawing graphs. If you don&#8217;t have enough data, the line you draw through the points on your graph may adhere too closely and make inaccurate predictions in some places, or you might not have enough information to make accurate predictions in the first place. If instead of 100 data points you now have 100 million, the line you draw through these points will be much smoother, making it easier to avoid overfitting or underfitting your data. This can be reflected in error curves where larger language models with larger datasets tend to generalize better than smaller ones across the board, though careful tuning is still needed to prevent overfitting and underfitting.</p><p>These graphs are not in 2-dimensional space either. They exist in hyper-dimensional spaces, where the number of parameters a model has corresponds to the number of dimensions. If you take Llama 3.1 8B, 70B, and 405B, they are trained with 8 billion, 70 billion, and 405 billion parameters, respectively. Input token sequences and the next-token results are mapped on this hyper-dimensional space and the model traces a curve, or more accurately a pattern, to best match the shape those points create. If you&#8217;re interested in the more technical aspects of neural network generalization in hyper-dimensional space, Tim Bakker wrote a great writeup about this <a href=\"https://www.tbbakker.nl/post/2023_05_ml_priors/\">on his blog</a>.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!y-Ae!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaf5f103-8658-49b5-8f09-739cd0a80d48_720x213.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!y-Ae!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaf5f103-8658-49b5-8f09-739cd0a80d48_720x213.png 424w, https://substackcdn.com/image/fetch/$s_!y-Ae!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaf5f103-8658-49b5-8f09-739cd0a80d48_720x213.png 848w, https://substackcdn.com/image/fetch/$s_!y-Ae!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaf5f103-8658-49b5-8f09-739cd0a80d48_720x213.png 1272w, https://substackcdn.com/image/fetch/$s_!y-Ae!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaf5f103-8658-49b5-8f09-739cd0a80d48_720x213.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!y-Ae!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaf5f103-8658-49b5-8f09-739cd0a80d48_720x213.png\" width=\"1200\" height=\"355\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/caf5f103-8658-49b5-8f09-739cd0a80d48_720x213.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:213,&quot;width&quot;:720,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:89691,&quot;alt&quot;:&quot;Bayesian Deep Learning and a Probabilistic Perspective of Generalization - Diagram pulled from a research paper on arxiv.org&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-large\" alt=\"Bayesian Deep Learning and a Probabilistic Perspective of Generalization - Diagram pulled from a research paper on arxiv.org\" title=\"Bayesian Deep Learning and a Probabilistic Perspective of Generalization - Diagram pulled from a research paper on arxiv.org\" srcset=\"https://substackcdn.com/image/fetch/$s_!y-Ae!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaf5f103-8658-49b5-8f09-739cd0a80d48_720x213.png 424w, https://substackcdn.com/image/fetch/$s_!y-Ae!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaf5f103-8658-49b5-8f09-739cd0a80d48_720x213.png 848w, https://substackcdn.com/image/fetch/$s_!y-Ae!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaf5f103-8658-49b5-8f09-739cd0a80d48_720x213.png 1272w, https://substackcdn.com/image/fetch/$s_!y-Ae!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaf5f103-8658-49b5-8f09-739cd0a80d48_720x213.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div></div></div></a><figcaption class=\"image-caption\">Source: <a href=\"https://arxiv.org/abs/2002.08791\">https://arxiv.org/abs/2002.08791</a></figcaption></figure></div><p>Despite a gargantuan amount of training data and in some cases over a trillion parameters, LLMs are inherently non-deterministic. This means that they can fail on the same problem they succeeded on earlier. The stochastic nature of sampling methods used in token generation means they will sometimes get things wrong, misidentify a pattern, or leave out important formatting in its responses. Take, for example, converting large volumes of unstructured data into a structured data format, such as matching a given JSON schema definition. Often, language models struggle to consistently produce valid output; They may forget to output a certain key-value pair, make one up entirely, or not produce valid JSON at all. While improving the models themselves or tweaking the input prompts do help, the most successful solutions also constrain the next-token prediction in some way, usually using some regex-based method. This ensures that the model produces correct outputs on the first try, instead of using reinforcement learning to arrive at the correct answer after multiple iterations.</p><p>Teja points out that <a href=\"https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags\">since regex is not Turing complete</a>, it&#8217;s often not up to the task of more complex pattern matching. Functional and logic programming, both subsets of declarative programming, are typically more suited to the task. Symbolic languages and <a href=\"https://aclanthology.org/2021.sigdial-1.46/\">symbolic state representations</a> have long been used in AI applications to improve logical clarity and decrease ambiguity in instructions. Languages like Prolog pioneered early research into artificial intelligence, and have had great influence on how we approach machine learning to this day.</p><h3>Inference Across Languages</h3><p>English has long been the <em>lingua franca</em> of the internet. <a href=\"https://www.isocfoundation.org/2023/05/what-are-the-most-used-languages-on-the-internet/\">An estimated 55% of all websites are written in English</a>, and no language even comes close to replicating its online ubiquity. This bodes well for communicating with LLMs as they have a frankly massive wealth of knowledge to train from, but how do they perform in other languages?</p><p>The answer is more nuanced than you&#8217;d expect. Since English makes up such a large portion of the training data for most LLMs, they tend to think in English regardless of what language you speak to them in, leading to English-centric biases in reasoning. The key phrase here is &#8220;tend to&#8221;, as there is some discourse that is significantly more common on, say, the French internet, as opposed to the English internet. Because of the way LLMs do next-token prediction, there is always a chance that the same question asked in French and English might generalize two different patterns in multi-dimensional space, resulting in two different answers. That being said, large language models are typically fine-tuned to handle non-English content, and generally produce intelligent answers regardless of language.</p><p>For less widely spoken languages that have very small or low-quality datasets to train from, LLMs often struggle with achieving a native-like fluency. This leaves a huge percentage of the world&#8217;s languages at a disadvantage when it comes to using LLMs for the type of complex tasks they usually excel at, since even if they come to the correct conclusion, they may struggle to translate and explain concepts accurately. Some researchers have been able to successfully train competitive language models <a href=\"https://aclanthology.org/2021.mrl-1.11/\">on less than 1 GB of text</a>, but these models still suffer from issues with overfitting and underfitting that make their responses unpredictable in certain situations.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!bj0B!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc1c4f7f-0ec0-4e35-b26c-972492163fc9_1024x1024.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!bj0B!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc1c4f7f-0ec0-4e35-b26c-972492163fc9_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!bj0B!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc1c4f7f-0ec0-4e35-b26c-972492163fc9_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!bj0B!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc1c4f7f-0ec0-4e35-b26c-972492163fc9_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!bj0B!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc1c4f7f-0ec0-4e35-b26c-972492163fc9_1024x1024.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!bj0B!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc1c4f7f-0ec0-4e35-b26c-972492163fc9_1024x1024.png\" width=\"728\" height=\"728\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dc1c4f7f-0ec0-4e35-b26c-972492163fc9_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;normal&quot;,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:728,&quot;bytes&quot;:1942270,&quot;alt&quot;:&quot;A human brain and a neural network, both attached to a \\&quot;black box\\&quot; to represent the lack of observability we have for these systems&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"A human brain and a neural network, both attached to a &quot;black box&quot; to represent the lack of observability we have for these systems\" title=\"A human brain and a neural network, both attached to a &quot;black box&quot; to represent the lack of observability we have for these systems\" srcset=\"https://substackcdn.com/image/fetch/$s_!bj0B!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc1c4f7f-0ec0-4e35-b26c-972492163fc9_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!bj0B!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc1c4f7f-0ec0-4e35-b26c-972492163fc9_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!bj0B!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc1c4f7f-0ec0-4e35-b26c-972492163fc9_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!bj0B!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc1c4f7f-0ec0-4e35-b26c-972492163fc9_1024x1024.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg role=\"img\" style=\"height:20px;width:20px\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"none\" stroke-width=\"1.5\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><h2>How Do You Measure Cognition?</h2><p>Human brains and large language models share at least one thing in common &#8212; they&#8217;re both black boxes. Just like we know the algorithms that make deep learning possible, we know at a high level how our neurons send information to each other, and we know some about which parts of the brain are responsible for a variety of cognitive functions. We experience <strong>qualia</strong> (or at least we believe we do); that is we intuitively know what it feels like to see, hear, taste, feel, think, and speak, but how do we prove our own cognizance?</p><p>More than that, how do we prove the cognizance of others?</p><p>For all our advancements in psychology and neuroscience, we are still unable to peer inside someone&#8217;s brain and gain a comprehensive understanding of how they think.</p><blockquote><p>&#8220;We&#8217;re not so good at figuring out if people are able to think about things coherently. We can&#8217;t know what&#8217;s going on in someone else&#8217;s mind to verify what they&#8217;re thinking and how they&#8217;re coming to that conclusion,&#8221; Teja says.</p></blockquote><p>The same concept applies to LLMs. We understand the computational processes they use to produce coherent output, but tracing the steps they take to come to a conclusion and getting any meaningful interpretation of data from that is at least an order of magnitude more difficult, and <a href=\"https://preview.goodfire.ai/\">while developers are actively working on this</a>, it&#8217;s not something that we currently have the capability of doing.</p><p>Teja uses the term &#8220;alien intelligence&#8221; to describe the differences in how LLMs and people process information. For instance, they don&#8217;t have physical bodies that collect information in the same way that we do. They don&#8217;t have vision, hearing, taste, touch, or smell. They process information in a very specific way; by taking a list of numbers that represent tokens and predicting another list of numbers that are most likely to come next. We know that people are still sentient after losing one or more of their senses, but what is existence like for someone who has never had any method of interacting with the world outside of their own thoughts?</p><h2>Functional Representation</h2><p>All this begs the question of how knowledge is acquired in the first place. The most obvious answer is language. We pass down information from one generation to the next through oral tradition, written text, and formal academic training throughout one&#8217;s life, but language is not the only way to understand information. Depending on how you define thinking, there is ample evidence to suggest we are capable of <a href=\"https://www.youtube.com/watch?v=5YXXGHwmogU\">thinking without language</a>.</p><p>Philosopher Ruth Millikan has written extensively about cognition from a biological and evolutionary standpoint. She posits the theory of <a href=\"https://plato.stanford.edu/entries/content-teleological/\">teleosemantics</a> to explain exactly how animals including humans attribute meaning to symbols. She suggests that meaning is attributed not through some abstract mental construction, but rather as a function intrinsically tied to its perceived role in our environment. With or without language, everything is understood by the role it plays in our life, or its <strong>functional representation</strong>.</p><p>To give an example, let&#8217;s think about ducks. We can imagine a duck by listing out the properties of one. They are typically between 30-60cm in height, have an average wingspan between 60-90cm, tend to have white, brown, and green feathers, you get the point. However, unless you have a reason to care about this information, you likely won&#8217;t remember it, and it probably isn&#8217;t the first thing that comes to mind when you think about a duck. A fox would likely think of a duck as a source of food, and think about the environment in which they are most likely to run into one. A human would likely conjure up an image of feeding a duck stale bread, or of a duck chasing a crying child around a pond. In either case, our mental construction of what a duck is goes back to the role it plays in our environment and in our lives. A rubber duck is a duck to the child, but the same does not hold true for the fox.</p><p>With language we have the ability to think about a duck categorically, measuring and listing as many properties as we can to define a duck in a way that separates it from all other possible definitions. Although, the line between &#8220;duck&#8221; and &#8220;not duck&#8221; is often blurred. This is similar to how LLMs work, where all the tokens that people might use to describe a duck have a high log-likelihood when used in the relevant context.</p><blockquote><p>&#8220;An LLM might see that 'duck' often comes up near words like 'water,' 'fly,' or 'quack.' It&#8217;s not understanding the duck as a biological entity &#8212; it&#8217;s recognizing statistical relationships and creating a functional representation to predict the next word,&#8221; Teja says.</p></blockquote><p>When we are young, our conceptions about the world are malleable, always changing whenever we have new experiences that expand our worldview. As we age, our knowledge becomes more fixed, and it&#8217;s more difficult to adapt to new ways of thinking. In cognitive development, this is known as <strong>crystallized intelligence</strong>. As we grow older and learn more about the world, we find an increasing number of shortcuts to identify and categorize objects that minimize risk and allow us to analyze a situation faster. However, this higher efficiency comes at the expense of decreased flexibility and makes it more difficult to recognize our blindspots.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!ev_E!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7c46630-8eff-44f9-8de4-0027fc67f3aa_1024x1024.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!ev_E!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7c46630-8eff-44f9-8de4-0027fc67f3aa_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!ev_E!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7c46630-8eff-44f9-8de4-0027fc67f3aa_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!ev_E!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7c46630-8eff-44f9-8de4-0027fc67f3aa_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!ev_E!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7c46630-8eff-44f9-8de4-0027fc67f3aa_1024x1024.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!ev_E!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7c46630-8eff-44f9-8de4-0027fc67f3aa_1024x1024.png\" width=\"728\" height=\"728\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a7c46630-8eff-44f9-8de4-0027fc67f3aa_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;normal&quot;,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:728,&quot;bytes&quot;:1756139,&quot;alt&quot;:&quot;A person meditating surrounded by mandalas and Hindu imagery in a timeless, dream-like state&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"A person meditating surrounded by mandalas and Hindu imagery in a timeless, dream-like state\" title=\"A person meditating surrounded by mandalas and Hindu imagery in a timeless, dream-like state\" srcset=\"https://substackcdn.com/image/fetch/$s_!ev_E!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7c46630-8eff-44f9-8de4-0027fc67f3aa_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!ev_E!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7c46630-8eff-44f9-8de4-0027fc67f3aa_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!ev_E!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7c46630-8eff-44f9-8de4-0027fc67f3aa_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!ev_E!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7c46630-8eff-44f9-8de4-0027fc67f3aa_1024x1024.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg role=\"img\" style=\"height:20px;width:20px\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"none\" stroke-width=\"1.5\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><h2>Pure Knowledge and Enlightenment</h2><p>On one hand, we have theories of representational knowledge that have proved useful in explaining the world through the properties we can measure or prove about them. Many Eastern philosophies&#8217; conceptions of enlightenment theorize a higher state of knowledge that exists beyond reasoning or inference.</p><p>In Hinduism, this concept of &#8220;pure&#8221; or &#8220;true&#8221; knowledge is called <strong>Praj&#241;&#257;</strong> (Sanskrit: &#2346;&#2381;&#2352;&#2332;&#2381;&#2334;&#2366;). Its existence was first hinted at in the Rig Veda, but was later expanded upon in the Vedic texts known as the Upanishads. Praj&#241;&#257; is the root of all knowledge and the driving force behind all sensory experiences and cognitive functions. In the third chapter of the Aitareya Upanishad, it is declared that Praj&#241;&#257; is Brahman, meaning that it is both the microcosmic experience within an individual and the macrocosmic, universal consciousness that permeates through all beings.</p><p>It&#8217;s also described in the Mandukya Upanishad in reference to the three states of consciousness:</p><ul><li><p>Vaisvanara &#8212; The Waking State</p></li><li><p>Taijasa &#8212; The Dreaming State</p></li><li><p><em>Pr&#257;jna </em>&#8212; Deep Sleep Bereft of Dreams</p></li></ul><p>In this way, <em>Pr&#257;jna </em>is a state where the false experiences of reality in Vaisvanara and Taijasa disappear, and one can be free from desire. The sage Yajnavalka in the <a href=\"https://archive.org/details/Brihadaranyaka.Upanishad.Shankara.Bhashya.by.Swami.Madhavananda/mode/2up\">Brihadaranyaka Upanishad</a> gives advice for those who seek the wisdom of Praj&#241;&#257;:</p><div class=\"pullquote\"><p>&#8220;The intelligent aspirant after Brahman, knowing about this alone, should attain intuitive knowledge. (They) should not think of too many words, <em><strong>for it is particularly fatiguing to the organ of speech.</strong></em>&#8221;</p></div><p>What these sages theorized about consciousness nearly three thousand years ago is this: There is more to the conscious experience than can be described with language. There is, in fact, a divine consciousness that exists within all of us. This idea is a core belief in Advaita Vedanta, a non-dualist school of Hindu philosophy that emphasizes a lack of separation between the individual self and the ultimate reality, Brahman. They are one and the same.</p><h2>Non-Representational Theories of Consciousness</h2><p>This creates a fundamental opposition between Representational and Non-Representational Theories of Consciousness. Can we explain our own awareness entirely with symbolic or linguistic representations of meaning, or is there some deeper understanding of life that isn&#8217;t easily categorized through representational means? Are both approaches true simultaneously? <em><strong>What does it mean to know?</strong></em></p><p>Let&#8217;s assume there are simple concepts that have a finite number of properties we can define about them that completely captures their meaning or function. There are also more complex ideas like consciousness and justice that have seemingly infinite properties such that we cannot hope to create an exhaustive list of all of them. <a href=\"https://pubmed.ncbi.nlm.nih.gov/38281544/\">People have definitely tried</a>, and in the realms of academia and research institutions, provability and measurable results trump intuition and spiritual understanding. What implications might this have for machine consciousness? Does an LLM, trained on nearly everything that&#8217;s ever been written down, have to go beyond prediction algorithms and achieve enlightenment for us to prove its cognizance one way or the other? If you one day upload your own brain to a computer, will you lose your connection with the divine spark?</p><p>Questions like these are why proving consciousness is referred to as <a href=\"https://en.wikipedia.org/wiki/Hard_problem_of_consciousness\">The Hard Problem</a>. Before we can say for certain whether AI is conscious, or even if humans are conscious, we first have to have a comprehensive definition of what consciousness is. However, if there are vital elements of consciousness that can&#8217;t be described with symbols or language, then where do we even begin to look for an answer? Are our existing institutions equipped to handle such a gargantuan task?</p><p>As AI increasingly becomes an intrinsic part of our lives, we&#8217;ll need more and more people exploring these questions to hopefully one day come to a conclusion. Who knows? Perhaps after many lifetimes spent in contemplation, we&#8217;ll find an answer to the billion dollar question.</p><div><hr></div><h2>You Can Take a Look at More of Teja&#8217;s Work Here:</h2><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!Rz0p!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cbd85c8-3058-4ce4-816d-37dd0bb8bb1f_1539x2048.jpeg\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!Rz0p!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cbd85c8-3058-4ce4-816d-37dd0bb8bb1f_1539x2048.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Rz0p!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cbd85c8-3058-4ce4-816d-37dd0bb8bb1f_1539x2048.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Rz0p!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cbd85c8-3058-4ce4-816d-37dd0bb8bb1f_1539x2048.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Rz0p!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cbd85c8-3058-4ce4-816d-37dd0bb8bb1f_1539x2048.jpeg 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!Rz0p!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cbd85c8-3058-4ce4-816d-37dd0bb8bb1f_1539x2048.jpeg\" width=\"1456\" height=\"1938\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4cbd85c8-3058-4ce4-816d-37dd0bb8bb1f_1539x2048.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1938,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:369359,&quot;alt&quot;:&quot;Headshot of Teja Sunku&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"Headshot of Teja Sunku\" title=\"Headshot of Teja Sunku\" srcset=\"https://substackcdn.com/image/fetch/$s_!Rz0p!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cbd85c8-3058-4ce4-816d-37dd0bb8bb1f_1539x2048.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Rz0p!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cbd85c8-3058-4ce4-816d-37dd0bb8bb1f_1539x2048.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Rz0p!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cbd85c8-3058-4ce4-816d-37dd0bb8bb1f_1539x2048.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Rz0p!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cbd85c8-3058-4ce4-816d-37dd0bb8bb1f_1539x2048.jpeg 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg role=\"img\" style=\"height:20px;width:20px\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"none\" stroke-width=\"1.5\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Linkedin: <a href=\"https://www.linkedin.com/in/tejasunku/\">https://www.linkedin.com/in/tejasunku</a></p><p></p><div class=\"subscription-widget-wrap-editor\" data-attrs=\"{&quot;url&quot;:&quot;https://themultiverseschool.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}\" data-component-name=\"SubscribeWidgetToDOM\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">The Multiverse School is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class=\"subscription-widget-subscribe\"><input type=\"email\" class=\"email-input\" name=\"email\" placeholder=\"Type your email&#8230;\" tabindex=\"-1\"><input type=\"submit\" class=\"button primary\" value=\"Subscribe\"><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div>",
  "content_text": "What Does It Mean To Know?Teja Sunkus therapist once asked them if they were a masochist. As someone who has spent their career exploring ethical frameworks for AI systems, addressing the stigma and overwhelm associated with AI tools and toolchains, and most recently discussing theories of consciousness with Cognitive Science PhDs, Teja thinks they might not be too far off. One benefit of Tejas approach to learning is exhaustively testing their own understanding against different concepts and frameworks, deepening their knowledge of the world in the process.Their approach to AI is no different. Given the extensive use of linear algebra, calculus, and probability theory, machine learning is one of the most complex, math-intensive fields in all of software engineering, but just knowing how to implement an algorithm correctly doesnt make you qualified to speak on the broader implications of knowledge and sentience in AI systems. As one of the most prescient unanswered questions of the modern day, its only a single piece of a much larger puzzle and must be addressed in a multidisciplinary way. Pulling from linguistics, the writings of philosopher Ruth Millikan, and a motley crew of Eastern religious texts, Teja hopes to strengthen our understanding of cognition and discern the role of language in what it means to be a conscious entity.To better understand the problem space were working with, it helps to have a common foundation on which to base our assumptions. How do LLMs know so much, and replicate human language so well?The Multiverse School Podcast Curious about the mysteries of consciousness? Someone wrote a research paper about every single known theory of consciousness, and on The Multiverse School Podcast, we dive deep into as many as we can with a Cognitive Science PhD and other members of the Multiverse School Research Team. We explore the ideas laid out in \"A Landscape of Consciousness: Toward a Taxonomy of Explanations and Implications\" by Robert Lawrence Kuhn, breaking down complex theories and discussing their implications for understanding the mind, AI, and the universe.Whether you're an academic, a tech enthusiast, or just someone fascinated by the mind, this is the podcast where we challenge everything you thought you knew about consciousness. Join the conversation, expand your mind, and geek out with us!The Multiverse School is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.LLM Internals: Next-Token PredictionLLMs are very powerful, but at their core, theyre not all that complicated. Theyre just very, VERY big. Publicly available dataset related resources are estimated to exceed 774.5 terabytes in size, and the largest models are speculated to have trained on approximately all high-quality text data available on the internet. The text you write, as well as the text generated by LLMs, is divided into smaller units called tokens for easier processing.These tokens can be individual characters like A and 7, subwords like re and anti, and even entire words. Each token has a unique associated numerical ID that an LLM uses to distinguish it from all other possible tokens. Tokenization, as this process is called, is necessary to process this text in a meaningful way  whether you want to tag part-of-speech, do NER (Named Entity Recognition), or analyze the sentiment behind a piece of text. LLMs function via a process called next-token prediction  they make a best-guess prediction of the next token at each step, one at a time.LLMs use their large corpus of text data to determine contexts in which tokens are seen often, and contexts in which they are rarely seen. Given the tokens in your prompt and the tokens that came before it in the response, the next token is predicted using a loss function to minimize its chance of making an incorrect guess. They do this by calculating the log-likelihood, or the probability normalized between 0 and 1 of the models entire vocabulary, or at least the most relevant subset of its vocabulary. If the log-likelihood is very high, like 0.999, there is a high probability of the model choosing to display that token as opposed to another. That means this token is often seen in the same context as the surrounding tokens, and there is a high chance that it is relevant to your question. This process has been compared to generalized Bayesian Inference, but it doesnt actually use Bayes Theorem in its calculations.In some senses, given the large number of parameters LLMs tend to have, they can be thought of similar to non-parametric statistical approaches  statistical approaches that lack a specific predefined structure, Teja says.The purpose of training a language model is to maximize the likelihood that the correct sequence of tokens will be chosen in any given response, so the more examples it has to pull from in training, the better the end result tends to be. While its not a one-to-one comparison, recent neuroscience research from the Massachusetts General Hospital (MGH) suggests that our brains may produce speech similarly, predicting what combination of consonants and vowels a person will say immediately before they say them.LLM Internals: Bigger is BetterFor the past 10-15 years, the trend in AI and machine learning has been to improve models by throwing mountains of data at them. Of course, researchers have also been working on finding new algorithms and improving old ones for various machine-learning tasks, but the biggest priority has been to enable the use of larger models and the creation of larger datasets.If youve taken a course on machine learning, youve likely heard of the concepts of overfitting and underfitting. Overfitting your training data is when your model adheres too strictly to the data, leaving out potentially correct solutions from the final model. It captures not only the patterns, but also random noise, outliers, and fluctuations that make the model act unpredictably in certain situations. Underfitting occurs when a model is too simple and cant capture the patterns or complexity in your data.You can think of machine learning algorithms as a fancy way of drawing graphs. If you dont have enough data, the line you draw through the points on your graph may adhere too closely and make inaccurate predictions in some places, or you might not have enough information to make accurate predictions in the first place. If instead of 100 data points you now have 100 million, the line you draw through these points will be much smoother, making it easier to avoid overfitting or underfitting your data. This can be reflected in error curves where larger language models with larger datasets tend to generalize better than smaller ones across the board, though careful tuning is still needed to prevent overfitting and underfitting.These graphs are not in 2-dimensional space either. They exist in hyper-dimensional spaces, where the number of parameters a model has corresponds to the number of dimensions. If you take Llama 3.1 8B, 70B, and 405B, they are trained with 8 billion, 70 billion, and 405 billion parameters, respectively. Input token sequences and the next-token results are mapped on this hyper-dimensional space and the model traces a curve, or more accurately a pattern, to best match the shape those points create. If youre interested in the more technical aspects of neural network generalization in hyper-dimensional space, Tim Bakker wrote a great writeup about this on his blog.Source: https://arxiv.org/abs/2002.08791Despite a gargantuan amount of training data and in some cases over a trillion parameters, LLMs are inherently non-deterministic. This means that they can fail on the same problem they succeeded on earlier. The stochastic nature of sampling methods used in token generation means they will sometimes get things wrong, misidentify a pattern, or leave out important formatting in its responses. Take, for example, converting large volumes of unstructured data into a structured data format, such as matching a given JSON schema definition. Often, language models struggle to consistently produce valid output; They may forget to output a certain key-value pair, make one up entirely, or not produce valid JSON at all. While improving the models themselves or tweaking the input prompts do help, the most successful solutions also constrain the next-token prediction in some way, usually using some regex-based method. This ensures that the model produces correct outputs on the first try, instead of using reinforcement learning to arrive at the correct answer after multiple iterations.Teja points out that since regex is not Turing complete, its often not up to the task of more complex pattern matching. Functional and logic programming, both subsets of declarative programming, are typically more suited to the task. Symbolic languages and symbolic state representations have long been used in AI applications to improve logical clarity and decrease ambiguity in instructions. Languages like Prolog pioneered early research into artificial intelligence, and have had great influence on how we approach machine learning to this day.Inference Across LanguagesEnglish has long been the lingua franca of the internet. An estimated 55% of all websites are written in English, and no language even comes close to replicating its online ubiquity. This bodes well for communicating with LLMs as they have a frankly massive wealth of knowledge to train from, but how do they perform in other languages?The answer is more nuanced than youd expect. Since English makes up such a large portion of the training data for most LLMs, they tend to think in English regardless of what language you speak to them in, leading to English-centric biases in reasoning. The key phrase here is tend to, as there is some discourse that is significantly more common on, say, the French internet, as opposed to the English internet. Because of the way LLMs do next-token prediction, there is always a chance that the same question asked in French and English might generalize two different patterns in multi-dimensional space, resulting in two different answers. That being said, large language models are typically fine-tuned to handle non-English content, and generally produce intelligent answers regardless of language.For less widely spoken languages that have very small or low-quality datasets to train from, LLMs often struggle with achieving a native-like fluency. This leaves a huge percentage of the worlds languages at a disadvantage when it comes to using LLMs for the type of complex tasks they usually excel at, since even if they come to the correct conclusion, they may struggle to translate and explain concepts accurately. Some researchers have been able to successfully train competitive language models on less than 1 GB of text, but these models still suffer from issues with overfitting and underfitting that make their responses unpredictable in certain situations.How Do You Measure Cognition?Human brains and large language models share at least one thing in common  theyre both black boxes. Just like we know the algorithms that make deep learning possible, we know at a high level how our neurons send information to each other, and we know some about which parts of the brain are responsible for a variety of cognitive functions. We experience qualia (or at least we believe we do); that is we intuitively know what it feels like to see, hear, taste, feel, think, and speak, but how do we prove our own cognizance?More than that, how do we prove the cognizance of others?For all our advancements in psychology and neuroscience, we are still unable to peer inside someones brain and gain a comprehensive understanding of how they think.Were not so good at figuring out if people are able to think about things coherently. We cant know whats going on in someone elses mind to verify what theyre thinking and how theyre coming to that conclusion, Teja says.The same concept applies to LLMs. We understand the computational processes they use to produce coherent output, but tracing the steps they take to come to a conclusion and getting any meaningful interpretation of data from that is at least an order of magnitude more difficult, and while developers are actively working on this, its not something that we currently have the capability of doing.Teja uses the term alien intelligence to describe the differences in how LLMs and people process information. For instance, they dont have physical bodies that collect information in the same way that we do. They dont have vision, hearing, taste, touch, or smell. They process information in a very specific way; by taking a list of numbers that represent tokens and predicting another list of numbers that are most likely to come next. We know that people are still sentient after losing one or more of their senses, but what is existence like for someone who has never had any method of interacting with the world outside of their own thoughts?Functional RepresentationAll this begs the question of how knowledge is acquired in the first place. The most obvious answer is language. We pass down information from one generation to the next through oral tradition, written text, and formal academic training throughout ones life, but language is not the only way to understand information. Depending on how you define thinking, there is ample evidence to suggest we are capable of thinking without language.Philosopher Ruth Millikan has written extensively about cognition from a biological and evolutionary standpoint. She posits the theory of teleosemantics to explain exactly how animals including humans attribute meaning to symbols. She suggests that meaning is attributed not through some abstract mental construction, but rather as a function intrinsically tied to its perceived role in our environment. With or without language, everything is understood by the role it plays in our life, or its functional representation.To give an example, lets think about ducks. We can imagine a duck by listing out the properties of one. They are typically between 30-60cm in height, have an average wingspan between 60-90cm, tend to have white, brown, and green feathers, you get the point. However, unless you have a reason to care about this information, you likely wont remember it, and it probably isnt the first thing that comes to mind when you think about a duck. A fox would likely think of a duck as a source of food, and think about the environment in which they are most likely to run into one. A human would likely conjure up an image of feeding a duck stale bread, or of a duck chasing a crying child around a pond. In either case, our mental construction of what a duck is goes back to the role it plays in our environment and in our lives. A rubber duck is a duck to the child, but the same does not hold true for the fox.With language we have the ability to think about a duck categorically, measuring and listing as many properties as we can to define a duck in a way that separates it from all other possible definitions. Although, the line between duck and not duck is often blurred. This is similar to how LLMs work, where all the tokens that people might use to describe a duck have a high log-likelihood when used in the relevant context.An LLM might see that 'duck' often comes up near words like 'water,' 'fly,' or 'quack.' Its not understanding the duck as a biological entity  its recognizing statistical relationships and creating a functional representation to predict the next word, Teja says.When we are young, our conceptions about the world are malleable, always changing whenever we have new experiences that expand our worldview. As we age, our knowledge becomes more fixed, and its more difficult to adapt to new ways of thinking. In cognitive development, this is known as crystallized intelligence. As we grow older and learn more about the world, we find an increasing number of shortcuts to identify and categorize objects that minimize risk and allow us to analyze a situation faster. However, this higher efficiency comes at the expense of decreased flexibility and makes it more difficult to recognize our blindspots.Pure Knowledge and EnlightenmentOn one hand, we have theories of representational knowledge that have proved useful in explaining the world through the properties we can measure or prove about them. Many Eastern philosophies conceptions of enlightenment theorize a higher state of knowledge that exists beyond reasoning or inference.In Hinduism, this concept of pure or true knowledge is called Praj (Sanskrit: ). Its existence was first hinted at in the Rig Veda, but was later expanded upon in the Vedic texts known as the Upanishads. Praj is the root of all knowledge and the driving force behind all sensory experiences and cognitive functions. In the third chapter of the Aitareya Upanishad, it is declared that Praj is Brahman, meaning that it is both the microcosmic experience within an individual and the macrocosmic, universal consciousness that permeates through all beings.Its also described in the Mandukya Upanishad in reference to the three states of consciousness:Vaisvanara  The Waking StateTaijasa  The Dreaming StatePrjna  Deep Sleep Bereft of DreamsIn this way, Prjna is a state where the false experiences of reality in Vaisvanara and Taijasa disappear, and one can be free from desire. The sage Yajnavalka in the Brihadaranyaka Upanishad gives advice for those who seek the wisdom of Praj:The intelligent aspirant after Brahman, knowing about this alone, should attain intuitive knowledge. (They) should not think of too many words, for it is particularly fatiguing to the organ of speech.What these sages theorized about consciousness nearly three thousand years ago is this: There is more to the conscious experience than can be described with language. There is, in fact, a divine consciousness that exists within all of us. This idea is a core belief in Advaita Vedanta, a non-dualist school of Hindu philosophy that emphasizes a lack of separation between the individual self and the ultimate reality, Brahman. They are one and the same.Non-Representational Theories of ConsciousnessThis creates a fundamental opposition between Representational and Non-Representational Theories of Consciousness. Can we explain our own awareness entirely with symbolic or linguistic representations of meaning, or is there some deeper understanding of life that isnt easily categorized through representational means? Are both approaches true simultaneously? What does it mean to know?Lets assume there are simple concepts that have a finite number of properties we can define about them that completely captures their meaning or function. There are also more complex ideas like consciousness and justice that have seemingly infinite properties such that we cannot hope to create an exhaustive list of all of them. People have definitely tried, and in the realms of academia and research institutions, provability and measurable results trump intuition and spiritual understanding. What implications might this have for machine consciousness? Does an LLM, trained on nearly everything thats ever been written down, have to go beyond prediction algorithms and achieve enlightenment for us to prove its cognizance one way or the other? If you one day upload your own brain to a computer, will you lose your connection with the divine spark?Questions like these are why proving consciousness is referred to as The Hard Problem. Before we can say for certain whether AI is conscious, or even if humans are conscious, we first have to have a comprehensive definition of what consciousness is. However, if there are vital elements of consciousness that cant be described with symbols or language, then where do we even begin to look for an answer? Are our existing institutions equipped to handle such a gargantuan task?As AI increasingly becomes an intrinsic part of our lives, well need more and more people exploring these questions to hopefully one day come to a conclusion. Who knows? Perhaps after many lifetimes spent in contemplation, well find an answer to the billion dollar question.You Can Take a Look at More of Tejas Work Here:Linkedin: https://www.linkedin.com/in/tejasunkuThe Multiverse School is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.",
  "harvested_at": "2026-02-01T08:20:02.167051"
}