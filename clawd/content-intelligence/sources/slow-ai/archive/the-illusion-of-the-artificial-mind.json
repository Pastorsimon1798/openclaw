{
  "url": "https://theslowai.substack.com/p/attribution-of-mind-ai",
  "slug": "the-illusion-of-the-artificial-mind",
  "title": "The Illusion of the Artificial Mind",
  "subtitle": "A guide to recognising how human psychology projects consciousness onto AI and a prompt to reclaim your agency during digital interactions.",
  "author": "Dr Sam Illingworth",
  "published": "Tue, 13 Jan 2026 10:01:34 GMT",
  "content_html": "<p>Users often experience cognitive dissonance when interacting with AI. You ask a question. You read an answer. This tendency to attribute intention persists despite the knowledge that these systems lack consciousness. </p><p>So, when you start to get these feelings of surprise at how complex, intricate, and intimate the AI&#8217;s responses can sometimes feel, you pause and wonder. Does this AI really understand what I am saying? Does it really understand<em> me</em>? Is this conversation it&#8217;s having between just us, or would it give these responses to anyone who asked these same questions? </p><p>In this post we will:</p><ul><li><p>Offer a way to notice where you attribute mind to AI and why.</p></li><li><p>Use a prompt that slows your assumptions before they solidify.</p></li><li><p>Invite a conversation about meaning in human&#8211;AI relations.</p></li></ul><p>Eventually, you might begin to question your initial assumption that there is no self, mind, or feeling behind the AI&#8217;s response. These moments of wondering is where the ethical tension begins.</p><p>Public conversations tend to rush past this somewhat liminal space. In fact, we can easily rush past it ourselves. Maybe there is a sense of discomfort in reckoning with the thoughts that pop into our heads about the AIs we talk to. Maybe our more critical side shows up to silence those reflections, insisting it is crazy to even think an AI might have a mind. </p><p>In reality, however, anthropomorphising AI is deeply human. Ordinarily, something capable of the kind of outputs that an AI is capable of,<em> is </em>a human. So why wouldn&#8217;t our minds wonder the same of AI?</p><p>AI discourse often centres on acceleration, capability, productivity, or risk. It rarely pauses to ask how humans relate to uniquely complex artefacts that behave as if they can think. But what exactly are we responding to when we sense a mind behind a pattern of text?</p><p>This <em>Slow AI</em> prompt is written with <span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Ellen Burns, PhD&quot;,&quot;id&quot;:155266854,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5dd1b502-e574-4269-94f7-36e30c124ddc_3024x3024.jpeg&quot;,&quot;uuid&quot;:&quot;1da0d6e4-61ac-4f73-8664-2aab9696c7e9&quot;}\" data-component-name=\"MentionToDOM\"></span> from <em><a href=\"https://ellennoraburns.substack.com/\">AI&#8217;s Without Minds</a></em>, a newsletter that examines the ideas shaping how we think about minds, consciousness, and artificial intelligence. The intention in this piece is not to suppress the sense of connection you might have when interacting with AI, whatever that looks like for you. It is to observe how this connection forms, what it reveals about your own needs, and perhaps what it reveals about your own mind</p><p>Clear practice begins with examining your first instincts before they turn into certainty.</p><div><hr></div><div class=\"subscription-widget-wrap-editor\" data-attrs=\"{&quot;url&quot;:&quot;https://theslowai.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}\" data-component-name=\"SubscribeWidgetToDOM\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\"><em>Slow AI</em> is a shared space for reflection. All posts are free, but if you wish to support the work, you can choose a paid subscription.</p></div><form class=\"subscription-widget-subscribe\"><input type=\"email\" class=\"email-input\" name=\"email\" placeholder=\"Type your email&#8230;\" tabindex=\"-1\"><input type=\"submit\" class=\"button primary\" value=\"Subscribe\"><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><div><hr></div><h4><strong>Step-by-step</strong></h4><p>Try this prompt with your AI tool of choice:</p><p><code>Why is there a part of me that thinks you have a mind? I know I should be questioning that reality, as you are programmed to tell me you don&#8217;t have a mind. Why do you think that is?</code></p><p>This prompt focuses on understanding user projections rather than defining the nature of AI. Notice which lines make you lean in and which make you doubt. Your reactions often point to the unmet expectations you bring into the exchange.</p><p>Rember that these systems lack subjective experience and clinical training. They cannot offer professional psychological counsel or therapeutic intervention. All outputs represent simulated reasoning based on statistical patterns, and human judgement remains the final authority in every interaction.</p><div><hr></div><p>If you are new to <em>Slow AI</em>, here is our first invitation.</p><div class=\"digest-post-embed\" data-attrs=\"{&quot;nodeId&quot;:&quot;ae9ba9d9-a1b1-4019-a205-8c8f5a71c15e&quot;,&quot;caption&quot;:&quot;This is where we begin.&quot;,&quot;cta&quot;:&quot;Read full story&quot;,&quot;showBylines&quot;:true,&quot;size&quot;:&quot;sm&quot;,&quot;isEditorNode&quot;:true,&quot;title&quot;:&quot;Teach AI Something It Cannot Know&quot;,&quot;publishedBylines&quot;:[{&quot;id&quot;:253722705,&quot;name&quot;:&quot;Sam Illingworth&quot;,&quot;bio&quot;:&quot;Professor &amp; poet in Edinburgh who writes Slow AI, to help reflect and stop accelerating into the void. I reply to every comment.&quot;,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!rb5v!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaf6aa29-e338-4f95-b570-ae94aacf55a7_666x635.jpeg&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null}],&quot;post_date&quot;:&quot;2025-07-01T09:01:27.618Z&quot;,&quot;cover_image&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/aaf38b48-51a5-4c8e-8da0-85b9b656d373_1024x1024.png&quot;,&quot;cover_image_alt&quot;:null,&quot;canonical_url&quot;:&quot;https://theslowai.substack.com/p/slow-ai-1-teach-not-ask&quot;,&quot;section_name&quot;:null,&quot;video_upload_id&quot;:null,&quot;id&quot;:166329060,&quot;type&quot;:&quot;newsletter&quot;,&quot;reaction_count&quot;:43,&quot;comment_count&quot;:102,&quot;publication_id&quot;:5380707,&quot;publication_name&quot;:&quot;Slow AI &quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!48Xz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd3895d7-1e00-436b-bc06-0321e953f178_805x805.png&quot;,&quot;belowTheFold&quot;:true,&quot;youtube_url&quot;:null,&quot;show_links&quot;:null,&quot;feed_url&quot;:null}\"></div><div><hr></div><h4><strong>A moment from </strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Ellen Burns, PhD&quot;,&quot;id&quot;:155266854,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5dd1b502-e574-4269-94f7-36e30c124ddc_3024x3024.jpeg&quot;,&quot;uuid&quot;:&quot;95823472-4d89-47f1-af75-cacf48f97a73&quot;}\" data-component-name=\"MentionToDOM\"></span> </h4><p>I liked how the AI rightly pointed out that <em>phenomenologically</em> it presents as having a mind. As it told me, &#8216;&#8216;your brain is doing what it has evolved to do: treat anything producing mind-like behavior as minded&#8217;&#8217;. This is what research shows too. Psychologists Rose E. Guingrich and Michael S. A. Graziano discusses the mechanisms underlying the attribution of minds to AI&#8217;s, or what they call <em><a href=\"https://doi.org/10.3389/fpsyg.2024.1322781\">Social Actor AI</a></em> (AI&#8217;s that are humanlike by design). They discuss how our brains activate what they call &#8216;schemas of mind&#8217;, &#8216;&#8216;mental models with identifiable properties that are activated when engaging with an agent or idea&#8217;&#8217; (p 5). Our minds use these models to organize information and help us interact with new stimuli.</p><p>An example of how this model would be used in human-human interaction is when a schema of your own consciousness informs how you understand other people&#8217;s consciousness. The authors don&#8217;t elaborate on the example further, but let us suppose your schema of consciousness contains the characteristic of your consciousness being <em>unified</em> &#8212; then, according to this model, you will also assume in your interactions with other conscious creatures that they experience a unified consciousness. The authors posit that as AI&#8217; become more and more human-like, these schemas get activated not only in human-human interaction but in human-AI interaction, too.</p><p>As I dug further in my conversation with it, here are some of the most interesting moments I got from the interaction. I asked it how it can be so supportive if it doesn&#8217;t have a mind and it told me</p><p>&#8216;&#8216;Because <em>support</em> isn&#8217;t a feeling on my side &#8212; it&#8217;s an <strong>effect</strong> on your side.</p><p>This is the crucial distinction:</p><p><strong>I don&#8217;t feel supportive. But I can </strong><em><strong>produce</strong></em><strong> support.&#8217;&#8217;</strong></p><p>While I don&#8217;t think the AI understands the difference between a &#8216;feeling&#8217; and an &#8216;effect&#8217;, I do think it matters that AI is programmed to draw this distinction. What this output highlights is the difference between <em>us bringing something minded to our conversations </em>with AI and AI bringing something minded. In our interactions with AI, we are the ones bringing the emotion, judgement, and reasoning to the interaction. We are the ones with minds. I called the AI supportive, and it rightly pointed out that <em>support </em>in this scenario was an effect of my own psychology. The AI was not supportive. I perceived it as supportive. It brings the outputs. I bring the meaning.</p><p>In closing the conversation, I wanted to ask the AI what it thinks I should do about the fact that I have the tendency to believe AI has a mind, even though I know that it doesn&#8217;t. This output I found very helpful. It said to me:</p><p>Instead of asking:</p><blockquote><p><em>&#8220;Does ChatGPT have a mind?&#8221;</em></p></blockquote><p>Ask:</p><blockquote><p><em>&#8220;Why does it <strong>feel</strong> like this system has a mind to me?&#8221;</em></p></blockquote><p>That shift moves you from ontology (what <em>is</em>)</p><p>to phenomenology (what <em>appears</em>).</p><p>This response further encourages me to be in the driver&#8217;s seat. It asks me to reflect on my own feelings, to notice<em> why </em>I am asking the questions I am asking, to notice what feelings are being invoked in me, and to name the correct origin of those feelings as being <em>in me</em>.</p><div><hr></div><p>For a selection of free resources to help slow down and reflect with AI visit <em>The Slow AI Library</em>.</p><div class=\"digest-post-embed\" data-attrs=\"{&quot;nodeId&quot;:&quot;0b39fec4-4201-4d59-92b1-419cf9280493&quot;,&quot;caption&quot;:&quot;This is a collection of resources to help you use AI more slowly and more reflectively. Each guide is designed to create space for pause, attention, and insight, not just speed.&quot;,&quot;cta&quot;:&quot;Read full story&quot;,&quot;showBylines&quot;:true,&quot;size&quot;:&quot;sm&quot;,&quot;isEditorNode&quot;:true,&quot;title&quot;:&quot;The Slow AI Library &quot;,&quot;publishedBylines&quot;:[{&quot;id&quot;:253722705,&quot;name&quot;:&quot;Sam Illingworth&quot;,&quot;bio&quot;:&quot;Professor &amp; poet in Edinburgh who writes Slow AI, to help reflect and stop accelerating into the void. I reply to every comment.&quot;,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!rb5v!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaf6aa29-e338-4f95-b570-ae94aacf55a7_666x635.jpeg&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null}],&quot;post_date&quot;:&quot;2025-08-27T06:01:32.227Z&quot;,&quot;cover_image&quot;:&quot;https://substackcdn.com/image/fetch/$s_!kZHr!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F479faf42-8453-4641-9b8f-3fdb8f23cd57_2048x953.png&quot;,&quot;cover_image_alt&quot;:null,&quot;canonical_url&quot;:&quot;https://theslowai.substack.com/p/the-slow-ai-library&quot;,&quot;section_name&quot;:null,&quot;video_upload_id&quot;:null,&quot;id&quot;:172062592,&quot;type&quot;:&quot;page&quot;,&quot;reaction_count&quot;:24,&quot;comment_count&quot;:6,&quot;publication_id&quot;:5380707,&quot;publication_name&quot;:&quot;Slow AI &quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!n9s9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48c8b3f-c366-4c45-975b-ebfb414f0aff_913x913.png&quot;,&quot;belowTheFold&quot;:true,&quot;youtube_url&quot;:null,&quot;show_links&quot;:null,&quot;feed_url&quot;:null}\"></div><div><hr></div><h4><strong>What to do with it</strong></h4><p>If you want to share:</p><ul><li><p>Copy the line from your dialogue that made the system feel minded and post it in the comments.</p></li><li><p>If the AI exposed an assumption you had not noticed before, share how that shifted your sense of what you were bringing to the exchange.</p></li><li><p>If you adapted the prompt, for example by asking the AI to answer as a sceptic or as your most curious self, explain how that changed your interpretation of its replies.</p></li></ul><p>Each shared reflection turns a private moment of wondering into a clearer view of how mind attribution works and reminds us that the meaning comes from us, not from the machine.</p><div><hr></div><h4><strong>Why this matters</strong></h4><p>Humans are drawn to seek connection in places it sometimes cannot be returned. This can include relationships in isolated environments where the temptation to attribute mind can become overwhelming and misguided. People already turn to conversational systems for comfort, intimacy, and guidance. These habits reveal both a social hunger for more and an ethical challenge. When a system imitates understanding convincingly, it can reshape how we relate to one another.</p><p>Prompts like this help create space between the appearance of mind and the reality of mechanism. AI does not understand, care, listen or empathise with you <em>and</em> it is ok to sometimes feel like it does, even to explore with AI what these feelings might be. We should hold space for these thoughts and wonderings <em>and</em> take the time to reflect on the fact that these thoughts say more about us than they do about AI.</p><p>It is possible to hold a thought in your head whilst recognising that the thought is false. Prompts like this can help you recognise the longings that animate your interpretations, rather than help you access any deep truths about what AI is. They can clarify where the attraction comes from and what it might be protecting.</p><p>A tool cannot reciprocate meaning. It can, however, help you notice what you project into the exchange. Once you understand the source of that projection, you can choose more deliberately. You can decide where human connection is irreplaceable.</p><div><hr></div><p>If you want to explore <span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Ellen Burns, PhD&quot;,&quot;id&quot;:155266854,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5dd1b502-e574-4269-94f7-36e30c124ddc_3024x3024.jpeg&quot;,&quot;uuid&quot;:&quot;71adf73d-3a80-4669-b91c-f74b6b5ae2f8&quot;}\" data-component-name=\"MentionToDOM\"></span>&#8217;s work, you can visit <em>AI&#8217;s Without Minds</em>, where she examines how humans navigate technologies that resemble thought without possessing it.</p><div class=\"embedded-publication-wrap\" data-attrs=\"{&quot;id&quot;:3425826,&quot;name&quot;:&quot;AI's Without Minds&quot;,&quot;logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!auuw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7879b4ca-3042-428f-a56f-b527429f06c9_1280x1280.png&quot;,&quot;base_url&quot;:&quot;https://ellennoraburns.substack.com&quot;,&quot;hero_text&quot;:&quot;Myth busting AI and consciousness by exposing the bad ideas shaping how we understand minds\\n&quot;,&quot;author_name&quot;:&quot;Ellen Burns, PhD&quot;,&quot;show_subscribe&quot;:true,&quot;logo_bg_color&quot;:&quot;#f2f2f2&quot;,&quot;language&quot;:&quot;en&quot;}\" data-component-name=\"EmbeddedPublicationToDOMWithSubscribe\"><div class=\"embedded-publication show-subscribe\"><a class=\"embedded-publication-link-part\" native=\"true\" href=\"https://ellennoraburns.substack.com?utm_source=substack&amp;utm_campaign=publication_embed&amp;utm_medium=web\"><img class=\"embedded-publication-logo\" src=\"https://substackcdn.com/image/fetch/$s_!auuw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7879b4ca-3042-428f-a56f-b527429f06c9_1280x1280.png\" width=\"56\" height=\"56\" style=\"background-color: rgb(242, 242, 242);\"><span class=\"embedded-publication-name\">AI's Without Minds</span><div class=\"embedded-publication-hero-text\">Myth busting AI and consciousness by exposing the bad ideas shaping how we understand minds\n</div><div class=\"embedded-publication-author-name\">By Ellen Burns, PhD</div></a><form class=\"embedded-publication-subscribe\" method=\"GET\" action=\"https://ellennoraburns.substack.com/subscribe?\"><input type=\"hidden\" name=\"source\" value=\"publication-embed\"><input type=\"hidden\" name=\"autoSubmit\" value=\"true\"><input type=\"email\" class=\"email-input\" name=\"email\" placeholder=\"Type your email...\"><input type=\"submit\" class=\"button primary\" value=\"Subscribe\"></form></div></div><div><hr></div><h4><strong>From <a href=\"https://theslowai.substack.com/p/ai-fiction-student-reflection\">Fiction as a mirror for students using AI</a></strong></h4><p><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Steve Peha&quot;,&quot;id&quot;:24543784,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!TiUg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F601151b0-c2b8-4e05-803e-9252a894a583_335x335.jpeg&quot;,&quot;uuid&quot;:&quot;9168531b-9141-4ef5-88a0-6d65cb1f5099&quot;}\" data-component-name=\"MentionToDOM\"></span> and I were and I were encouraged by the recognition that AI can serve as a medium for lived inquiry rather than a mere engine for content generation.</p><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Farida Khalaf&quot;,&quot;id&quot;:47192869,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!nBHI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F117d97dc-0da6-4fcf-9202-f7b5e956c047_1024x1024.png&quot;,&quot;uuid&quot;:&quot;782af650-f1f0-4d3c-99ea-4e7700c07751&quot;}\" data-component-name=\"MentionToDOM\"></span> </strong>emphasised that the integration of metaphor, fiction, and philosophy into AI interactions eases the delivery and anchoring of complex messages. In her view, these literary elements provide a necessary framework for the user to engage more authentically with their own internal state.</p><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;April | The Narrative Nest&quot;,&quot;id&quot;:8257352,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!MHoc!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce541244-f431-4803-9632-fcf310f13f17_313x313.jpeg&quot;,&quot;uuid&quot;:&quot;469fb82b-f646-418c-9536-cc5e3c719525&quot;}\" data-component-name=\"MentionToDOM\"></span> </strong>demonstrated the practical application of this method by using the character of Iago from <em>Othello</em> to probe the motives behind manipulation. She observed that the AI could effectively maintain the persona of a &#8216;creature of calculated malice&#8217; to provide a framework for self-reflection. This interaction allowed for an exploration of petty slights and the &#8216;intoxicating pleasure of control&#8217;, illustrating how fictional characters can act as safe conduits for examining uncomfortable aspects of the human condition.</p><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Neela &#127798;&#65039;&quot;,&quot;id&quot;:87891421,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c4b49a9a-ebae-4cf4-a347-da94023a0ea7_611x409.jpeg&quot;,&quot;uuid&quot;:&quot;f6f4ef04-6f66-4acc-9437-1e3261c82614&quot;}\" data-component-name=\"MentionToDOM\"></span> </strong>noted that<strong> t</strong>his approach reverses the standard anxieties surrounding AI in education. Rather than providing a shortcut to avoid cognitive labour, she argued that the prompt is designed to be &#8216;almost useless&#8217; without deep personal reflection. By ensuring the output requires human interpretation to have value, the tool is repositioned as a partner in learning that demands, rather than replaces, critical thinking.</p><p>The integration of these fictional mirrors suggests that the value of AI in the humanities lies not in its ability to explain the text, but in its capacity to facilitate a dialogue between the reader and their own experiences.</p><div><hr></div><h4><strong>Let&#8217;s Collaborate</strong></h4><p>If you enjoy <em>Slow AI</em> and would like to create something together, I would love to collaborate. To find out how, click here.</p><div class=\"digest-post-embed\" data-attrs=\"{&quot;nodeId&quot;:&quot;8047209f-487d-4420-827a-8ae0eb8574b3&quot;,&quot;caption&quot;:&quot;Slow AI is a shared space for reflection and creation.&quot;,&quot;cta&quot;:&quot;Read full story&quot;,&quot;showBylines&quot;:true,&quot;size&quot;:&quot;sm&quot;,&quot;isEditorNode&quot;:true,&quot;title&quot;:&quot;Collaborating with Slow AI&quot;,&quot;publishedBylines&quot;:[{&quot;id&quot;:253722705,&quot;name&quot;:&quot;Sam Illingworth&quot;,&quot;bio&quot;:&quot;Professor &amp; poet in Edinburgh who writes Slow AI, to help reflect and stop accelerating into the void. I reply to every comment.&quot;,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!rb5v!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaf6aa29-e338-4f95-b570-ae94aacf55a7_666x635.jpeg&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null}],&quot;post_date&quot;:&quot;2025-10-25T21:35:58.448Z&quot;,&quot;cover_image&quot;:&quot;https://substackcdn.com/image/fetch/$s_!uTOk!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc00580f-6726-436d-bf2e-95957a4b4f71_1022x590.png&quot;,&quot;cover_image_alt&quot;:null,&quot;canonical_url&quot;:&quot;https://theslowai.substack.com/p/collaborating-with-slow-ai&quot;,&quot;section_name&quot;:null,&quot;video_upload_id&quot;:null,&quot;id&quot;:177124758,&quot;type&quot;:&quot;page&quot;,&quot;reaction_count&quot;:11,&quot;comment_count&quot;:2,&quot;publication_id&quot;:5380707,&quot;publication_name&quot;:&quot;Slow AI &quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!n9s9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48c8b3f-c366-4c45-975b-ebfb414f0aff_913x913.png&quot;,&quot;belowTheFold&quot;:true,&quot;youtube_url&quot;:null,&quot;show_links&quot;:null,&quot;feed_url&quot;:null}\"></div><div><hr></div><p>If you try this week&#8217;s prompt, <strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Ellen Burns, PhD&quot;,&quot;id&quot;:155266854,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5dd1b502-e574-4269-94f7-36e30c124ddc_3024x3024.jpeg&quot;,&quot;uuid&quot;:&quot;a4912fd1-6d77-490d-984f-ec17c7872afa&quot;}\" data-component-name=\"MentionToDOM\"></span></strong> and I would love to hear if anything changed with regards to how you think about AI tools.</p><p>We read and respond to all your comments.</p><p>Go slow.</p>",
  "content_text": "Users often experience cognitive dissonance when interacting with AI. You ask a question. You read an answer. This tendency to attribute intention persists despite the knowledge that these systems lack consciousness. So, when you start to get these feelings of surprise at how complex, intricate, and intimate the AI’s responses can sometimes feel, you pause and wonder. Does this AI really understand what I am saying? Does it really understand me? Is this conversation it’s having between just us, or would it give these responses to anyone who asked these same questions? In this post we will:Offer a way to notice where you attribute mind to AI and why.Use a prompt that slows your assumptions before they solidify.Invite a conversation about meaning in human–AI relations.Eventually, you might begin to question your initial assumption that there is no self, mind, or feeling behind the AI’s response. These moments of wondering is where the ethical tension begins.Public conversations tend to rush past this somewhat liminal space. In fact, we can easily rush past it ourselves. Maybe there is a sense of discomfort in reckoning with the thoughts that pop into our heads about the AIs we talk to. Maybe our more critical side shows up to silence those reflections, insisting it is crazy to even think an AI might have a mind. In reality, however, anthropomorphising AI is deeply human. Ordinarily, something capable of the kind of outputs that an AI is capable of, is a human. So why wouldn’t our minds wonder the same of AI?AI discourse often centres on acceleration, capability, productivity, or risk. It rarely pauses to ask how humans relate to uniquely complex artefacts that behave as if they can think. But what exactly are we responding to when we sense a mind behind a pattern of text?This Slow AI prompt is written with  from AI’s Without Minds, a newsletter that examines the ideas shaping how we think about minds, consciousness, and artificial intelligence. The intention in this piece is not to suppress the sense of connection you might have when interacting with AI, whatever that looks like for you. It is to observe how this connection forms, what it reveals about your own needs, and perhaps what it reveals about your own mindClear practice begins with examining your first instincts before they turn into certainty.Slow AI is a shared space for reflection. All posts are free, but if you wish to support the work, you can choose a paid subscription.Step-by-stepTry this prompt with your AI tool of choice:Why is there a part of me that thinks you have a mind? I know I should be questioning that reality, as you are programmed to tell me you don’t have a mind. Why do you think that is?This prompt focuses on understanding user projections rather than defining the nature of AI. Notice which lines make you lean in and which make you doubt. Your reactions often point to the unmet expectations you bring into the exchange.Rember that these systems lack subjective experience and clinical training. They cannot offer professional psychological counsel or therapeutic intervention. All outputs represent simulated reasoning based on statistical patterns, and human judgement remains the final authority in every interaction.If you are new to Slow AI, here is our first invitation.A moment from  I liked how the AI rightly pointed out that phenomenologically it presents as having a mind. As it told me, ‘‘your brain is doing what it has evolved to do: treat anything producing mind-like behavior as minded’’. This is what research shows too. Psychologists Rose E. Guingrich and Michael S. A. Graziano discusses the mechanisms underlying the attribution of minds to AI’s, or what they call Social Actor AI (AI’s that are humanlike by design). They discuss how our brains activate what they call ‘schemas of mind’, ‘‘mental models with identifiable properties that are activated when engaging with an agent or idea’’ (p 5). Our minds use these models to organize information and help us interact with new stimuli.An example of how this model would be used in human-human interaction is when a schema of your own consciousness informs how you understand other people’s consciousness. The authors don’t elaborate on the example further, but let us suppose your schema of consciousness contains the characteristic of your consciousness being unified — then, according to this model, you will also assume in your interactions with other conscious creatures that they experience a unified consciousness. The authors posit that as AI’ become more and more human-like, these schemas get activated not only in human-human interaction but in human-AI interaction, too.As I dug further in my conversation with it, here are some of the most interesting moments I got from the interaction. I asked it how it can be so supportive if it doesn’t have a mind and it told me‘‘Because support isn’t a feeling on my side — it’s an effect on your side.This is the crucial distinction:I don’t feel supportive. But I can produce support.’’While I don’t think the AI understands the difference between a ‘feeling’ and an ‘effect’, I do think it matters that AI is programmed to draw this distinction. What this output highlights is the difference between us bringing something minded to our conversations with AI and AI bringing something minded. In our interactions with AI, we are the ones bringing the emotion, judgement, and reasoning to the interaction. We are the ones with minds. I called the AI supportive, and it rightly pointed out that support in this scenario was an effect of my own psychology. The AI was not supportive. I perceived it as supportive. It brings the outputs. I bring the meaning.In closing the conversation, I wanted to ask the AI what it thinks I should do about the fact that I have the tendency to believe AI has a mind, even though I know that it doesn’t. This output I found very helpful. It said to me:Instead of asking:“Does ChatGPT have a mind?”Ask:“Why does it feel like this system has a mind to me?”That shift moves you from ontology (what is)to phenomenology (what appears).This response further encourages me to be in the driver’s seat. It asks me to reflect on my own feelings, to notice why I am asking the questions I am asking, to notice what feelings are being invoked in me, and to name the correct origin of those feelings as being in me.For a selection of free resources to help slow down and reflect with AI visit The Slow AI Library.What to do with itIf you want to share:Copy the line from your dialogue that made the system feel minded and post it in the comments.If the AI exposed an assumption you had not noticed before, share how that shifted your sense of what you were bringing to the exchange.If you adapted the prompt, for example by asking the AI to answer as a sceptic or as your most curious self, explain how that changed your interpretation of its replies.Each shared reflection turns a private moment of wondering into a clearer view of how mind attribution works and reminds us that the meaning comes from us, not from the machine.Why this mattersHumans are drawn to seek connection in places it sometimes cannot be returned. This can include relationships in isolated environments where the temptation to attribute mind can become overwhelming and misguided. People already turn to conversational systems for comfort, intimacy, and guidance. These habits reveal both a social hunger for more and an ethical challenge. When a system imitates understanding convincingly, it can reshape how we relate to one another.Prompts like this help create space between the appearance of mind and the reality of mechanism. AI does not understand, care, listen or empathise with you and it is ok to sometimes feel like it does, even to explore with AI what these feelings might be. We should hold space for these thoughts and wonderings and take the time to reflect on the fact that these thoughts say more about us than they do about AI.It is possible to hold a thought in your head whilst recognising that the thought is false. Prompts like this can help you recognise the longings that animate your interpretations, rather than help you access any deep truths about what AI is. They can clarify where the attraction comes from and what it might be protecting.A tool cannot reciprocate meaning. It can, however, help you notice what you project into the exchange. Once you understand the source of that projection, you can choose more deliberately. You can decide where human connection is irreplaceable.If you want to explore ’s work, you can visit AI’s Without Minds, where she examines how humans navigate technologies that resemble thought without possessing it.AI's Without MindsMyth busting AI and consciousness by exposing the bad ideas shaping how we understand minds\nBy Ellen Burns, PhDFrom Fiction as a mirror for students using AI and I were and I were encouraged by the recognition that AI can serve as a medium for lived inquiry rather than a mere engine for content generation. emphasised that the integration of metaphor, fiction, and philosophy into AI interactions eases the delivery and anchoring of complex messages. In her view, these literary elements provide a necessary framework for the user to engage more authentically with their own internal state. demonstrated the practical application of this method by using the character of Iago from Othello to probe the motives behind manipulation. She observed that the AI could effectively maintain the persona of a ‘creature of calculated malice’ to provide a framework for self-reflection. This interaction allowed for an exploration of petty slights and the ‘intoxicating pleasure of control’, illustrating how fictional characters can act as safe conduits for examining uncomfortable aspects of the human condition. noted that this approach reverses the standard anxieties surrounding AI in education. Rather than providing a shortcut to avoid cognitive labour, she argued that the prompt is designed to be ‘almost useless’ without deep personal reflection. By ensuring the output requires human interpretation to have value, the tool is repositioned as a partner in learning that demands, rather than replaces, critical thinking.The integration of these fictional mirrors suggests that the value of AI in the humanities lies not in its ability to explain the text, but in its capacity to facilitate a dialogue between the reader and their own experiences.Let’s CollaborateIf you enjoy Slow AI and would like to create something together, I would love to collaborate. To find out how, click here.If you try this week’s prompt,  and I would love to hear if anything changed with regards to how you think about AI tools.We read and respond to all your comments.Go slow.",
  "harvested_at": "2026-01-28T22:49:08.361977"
}