{
  "url": "https://theslowai.substack.com/p/are-ai-generated-images-theft",
  "slug": "are-ai-generated-images-theft",
  "title": "Are AI-generated Images Theft?",
  "subtitle": "A collaborative reflection on plagiarism, influence, and responsibility.",
  "author": "Dr Sam Illingworth",
  "published": "Mon, 22 Dec 2025 10:00:19 GMT",
  "content_html": "<p>This post began in a <a href=\"https://substack.com/@caitlinmccoll/note/c-187479388?utm_source=notes-share-action&amp;r=4725ox\">Note</a> on AI-generated images from <span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Caitlin McColl &#127464;&#127462;&quot;,&quot;id&quot;:31587167,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6b8fb43d-8575-42b3-b160-5b299043048f_347x609.jpeg&quot;,&quot;uuid&quot;:&quot;9d091a0d-5bd1-4e90-a6a0-563e19c66be8&quot;}\" data-component-name=\"MentionToDOM\"></span>, following on from <a href=\"https://substack.com/home/post/p-181366832\">a post about plagiarism in Substack Notes</a>. That earlier conversation was relatively clear. Copying someone else&#8217;s words and presenting them as your own is plagiarism. The harm is direct. The boundary is visible.</p><p>Images complicate this clarity.</p><p>In this post we will:</p><ul><li><p>Surface why AI generated images are often framed as theft, even when they are not copies.</p></li><li><p>Share perspectives from writers and artists with different stakes in the issue.</p></li><li><p>Hold space for disagreement without forcing resolution.</p></li></ul><div><hr></div><div class=\"subscription-widget-wrap-editor\" data-attrs=\"{&quot;url&quot;:&quot;https://theslowai.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}\" data-component-name=\"SubscribeWidgetToDOM\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\"><em>Slow AI</em> is a shared space for reflection. All posts are free, but if you wish to support the work, you can choose a paid subscription.</p></div><form class=\"subscription-widget-subscribe\"><input type=\"email\" class=\"email-input\" name=\"email\" placeholder=\"Type your email&#8230;\" tabindex=\"-1\"><input type=\"submit\" class=\"button primary\" value=\"Subscribe\"><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><div><hr></div><h4><strong>Why AI generated images feel different from text</strong></h4><p>When people accuse AI generated images of being theft, they are often responding to three things at once.</p><p>First, training data. Many image models were trained on copyrighted work without consent. That is not speculation. It is <a href=\"https://academic.oup.com/jiplp/article/20/3/182/7922541\">documented</a>. This is a corporate decision, not an individual one, but it shapes how every output is received.</p><p>Second, visibility. Images carry immediate aesthetic impact. A single image can do the work of many paragraphs. When an AI generated image replaces commissioned or credited art, the loss feels concrete.</p><p>Third, opacity. With text, influence has always been messy. Writers absorb voices, rhythms, and forms. With images, the lack of visible sources makes influence harder to judge. Without provenance, people assume the worst.</p><p>This combination explains the heat of the debate, even when the specific accusation does not hold.</p><div><hr></div><h4><strong>When AI starts to sound like you</strong></h4><p>Writing with AI can quietly flatten your voice and shift decisions you did not mean to hand over. <em>Keep Your Voice</em> is a <em>Slow AI</em> guide that shows how to stay present, deliberate, and in control when using AI tools to write.</p><p class=\"button-wrapper\" data-attrs=\"{&quot;url&quot;:&quot;https://samillingworth.gumroad.com/l/keep-your-voice&quot;,&quot;text&quot;:&quot;Download here&quot;,&quot;action&quot;:null,&quot;class&quot;:null}\" data-component-name=\"ButtonCreateButton\"><a class=\"button primary\" href=\"https://samillingworth.gumroad.com/l/keep-your-voice\"><span>Download here</span></a></p><div><hr></div><h4><strong>Perspectives from the community</strong></h4><p>My position, briefly, is that AI generated images are not theft in the same way as copying and passing off someone else&#8217;s work. Most outputs are novel combinations rather than replicas. That places them closer to uncredited influence than plagiarism. The problem is that we cannot see the sources. Without transparency, ethical judgement becomes guesswork. I would like platforms to show training sources or at least categories. Right now, we are arguing in the dark. However, my main income is not as an artist. If it were, I would probably weigh risk and harm differently.</p><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Mia Kiraki &#127917;&quot;,&quot;id&quot;:362428399,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!1Tql!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb399c9f8-2a30-48fe-a55e-c998a964e2c0_672x685.jpeg&quot;,&quot;uuid&quot;:&quot;6400becb-fd7f-4844-ae28-cf5dc0e8da89&quot;}\" data-component-name=\"MentionToDOM\"></span></strong></p><blockquote><p>I don&#8217;t experience most AI-generated images as theft so much as turbocharged influence, and those aren&#8217;t the same moral category. Theft to me is the deliberate copy-pasting of an actual artifact (or its core concept) and pretending it came from your hands. I love to always give this example when the topic comes up - art history is basically one long chain of visible &#8220;stealing&#8221;. Classical music too. It&#8217;s full of composers building whole works as variations of someone else&#8217;s theme where the transformation IS the actual point (Bach&#8217;s Passacaglia in C minor was directly inspired by Buxtehude&#8217;s version). AI models learn from existing work (just like every human artist), but the main question is, can we meaningfully regulate the difference between influence and theft? I don&#8217;t think we can, and until we do, my bias is super simple. Be honest about when AI helps and accept that pure originality is always a more comforting myth that we use to feel safe.</p></blockquote><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;ToxSec&quot;,&quot;id&quot;:8759131,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1a806452-e7f3-469b-bc9c-6598032d1595_500x500.png&quot;,&quot;uuid&quot;:&quot;bdc109a4-f30f-441a-838a-839a6e5e767b&quot;}\" data-component-name=\"MentionToDOM\"></span></strong></p><blockquote><p>I don&#8217;t think novel combinations are theft. Targeted replication? That&#8217;s a different animal.</p><p>Look, I use AI art tools constantly. My whole ToxSec aesthetic, the rust, the slime, the skull-at-the-terminal energy, took real iteration to dial in. When I see my work, I don&#8217;t feel like I stole from anyone. Same way comic artists didn&#8217;t steal from whoever drew the first panel. We absorb what we love, remix it, make something that feels like ours.</p><p>But here&#8217;s the line for me: if I scraped someone&#8217;s entire portfolio, trained a model on it, and started pumping out their exact vibe under my name? That&#8217;s theft. The pixels don&#8217;t have to be identical. What matters is I&#8217;m extracting the novel combination <em>they</em> built. The brand, the aesthetic fingerprint, the thing that makes their work recognizable as <em>theirs</em>. That&#8217;s what we actually own in creative work. Not individual images. The accumulated choices that become a signature.</p><p>The real problem isn&#8217;t the technology. We&#8217;re asking individual creators to police something that should be a platform-level responsibility. Most of us just want to make thin<strong>gs. </strong>We shouldn&#8217;t need law degrees to figure out if we crossed a line. </p></blockquote><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Caitlin McColl &#127464;&#127462;&quot;,&quot;id&quot;:31587167,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6b8fb43d-8575-42b3-b160-5b299043048f_347x609.jpeg&quot;,&quot;uuid&quot;:&quot;c7192d30-6b9d-4c2c-9a3a-49aa402f4164&quot;}\" data-component-name=\"MentionToDOM\"></span></strong></p><blockquote><p>I don&#8217;t see AI-generated images as outright theft, even though they are undeniably trained on artists&#8217; styles and techniques without consent, which is ethically uncomfortable. When someone uses prompts to create an image for something like a Substack article, the finished result is a unique combination of specific instructions and mixed influences, not a copied Monet or Van Gogh passed off as original work, for arguments sake. Artists have <em>always</em> learned from, absorbed, and echoed other artists, and unless you are explicitly asking an AI to replicate a named artist&#8217;s style, what you are doing is closer to imitation and synthesis than plagiarism.</p></blockquote><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Jenny Ouyang&quot;,&quot;id&quot;:282291554,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!DAbx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c08edab-ab02-4e7b-97b7-0c2aecea5e5a_1745x1479.jpeg&quot;,&quot;uuid&quot;:&quot;621c1f88-0341-45a8-a7f8-3912f1f84d78&quot;}\" data-component-name=\"MentionToDOM\"></span></strong></p><blockquote><p>I don&#8217;t see AI-generated images as theft, but two things bother me. First, when people persistently replicate someone else&#8217;s distinctive style without adding their own spirit - it&#8217;s not illegal, just hollow. Second, and this one&#8217;s personal: when I generate an image but haven&#8217;t put my own interpretation into it. If I&#8217;m just typing &#8220;inspiring entrepreneur at desk&#8221; and accepting whatever appears, I&#8217;ve created noise, not communication. The tool amplifies intent. If your intent is clear and specific, you get something useful. If it&#8217;s just &#8220;I need an image here,&#8221; you get generic filler that wastes everyone&#8217;s time. I&#8217;d rather focus on making sure what I create actually add<strong>s </strong>something worth reading.</p></blockquote><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;AI Meets Girlboss&quot;,&quot;id&quot;:415027717,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!A_s-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997a936d-cbbb-4ee7-95e9-a8a4ff789ed8_663x663.jpeg&quot;,&quot;uuid&quot;:&quot;d078f40e-d650-4d31-ace6-35e4039ba612&quot;}\" data-component-name=\"MentionToDOM\"></span></strong></p><blockquote><p>&#8220;Good artists copy, great artists steal.&#8221; Picasso said that a century before AI. What he meant with this: real innovation comes from gathering ideas everywhere, running them through your own creative chemistry set, and making something unmistakably yours and not copying something and hoping no one notices.</p><p>My Substack is visually driven, and AI is part of my creative toolkit. The way I work follows the same logic designers use when they build mood boards. Influence is how visual languages evolve. The line sits somewhere else. Borrowing a vibe is normal. Borrowing someone&#8217;s face, voice, or recognisable signature without consent is misappropriation with faster rendering. Think of the difference between Taylor Swift being pulled into a political campaign via AI images she never endorsed, versus Jennifer Lopez partnering on JenAI for Virgin Voyages was licensed, compensated and fully consensual. AI didn&#8217;t break the old rules of art; it just lit them up in neon so we finally have to look.</p></blockquote><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Karen Smiley&quot;,&quot;id&quot;:211311675,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!VT8w!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ff2e028-aa6a-4b0f-9154-df6c46aba4c8_800x800.jpeg&quot;,&quot;uuid&quot;:&quot;b02fc12b-7402-4de3-845c-df7f76be0ffa&quot;}\" data-component-name=\"MentionToDOM\"></span></strong></p><blockquote><p>Shaming people who use AI tools is not helpful. Any shaming should be aimed at the AI companies who steal copyrighted images without getting consent or giving credit or compensation (the 3Cs of creative rights, as CIPRI calls them). On the other hand, I also don&#8217;t think it&#8217;s ok to just say <em>&#8220;Oh well, too bad that artists&#8217; works and livelihoods have been stolen&#8221;</em> and merrily go along using AI tools built on exploiting their works.</p><p>We all deserve to have ethical AI tools to choose from. But with few exceptions, AI companies are only going to offer us ethical tools <em>if we, the users and consumers, compel them to build ethical tools</em>. </p><p>I agree fully with other commenters on transparency. We don&#8217;t all have to agree on whether we are ok with AI-generated imagery. But people who care strongly one way or another deserve to know. And more people being up-front about using AI should help to mitigate the un-helpful shaming.</p></blockquote><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Karen Spinner&quot;,&quot;id&quot;:363410124,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!kLy3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28ad1170-99e0-4cb6-8a1d-f4f60c4465ef_591x591.jpeg&quot;,&quot;uuid&quot;:&quot;3692b88b-fefd-4ec8-99de-fb7afbe4938d&quot;}\" data-component-name=\"MentionToDOM\"></span> </strong></p><blockquote><p>I spent a lot of time creating digital art by hand during the pandemic, and I even fine-tuned a Stable Diffusion model to imitate my style. (It didn&#8217;t work, the outputs were mediocre and quickly drifted back to the model&#8217;s core training data.) Real art is real work, and I can sympathize with artists who are losing jobs to generative AI. I think AI companies did steal their creations.</p><p>And yet, I&#8217;m also using generative AI to create consistent branding for my newsletter, which I see as &#8220;content&#8221; not &#8220;art.&#8221; (My use of AI is displacing free Canva, not trained artists.) And AI is so deeply enmeshed with modern creator tools that it&#8217;s getting increasingly difficult to draw the line between &#8220;AI-assisted&#8221; and &#8220;100% human.&#8221;</p><p>I hold contradictory views on this. I suspect a lot of people do.</p></blockquote><div><hr></div><h4><strong>What we are learning from this discussion</strong></h4><p>A few shared principles are emerging.</p><ul><li><p>Blame travels upward more effectively than sideways.</p></li><li><p>Transparency builds trust even when disagreement remains.</p></li><li><p>Context matters more than slogans.</p></li><li><p>Ethical use is a practice, not a label.</p></li></ul><p>For images, as for text, the question is less is this allowed and more what kind of space are we trying to build together.</p><div><hr></div><h4><strong>Why this matters</strong></h4><p><em>Slow AI</em> is about deliberate practice. AI generated images sit at a fault line between creativity and extraction. How we talk about them shapes norms long before policy catches up.</p><p>If we default to accusation, people hide. If we default to indifference, harm normalises.</p><p>A slower conversation leaves room for responsibility without collapse into purity tests.</p><p>If you have thoughts, experience, or disagreement, please add it below the line. There are no final answers here, only an opportunity to learn together.</p><p>We read and respond to all your comments.</p><p>Go slow.</p><p></p>",
  "content_text": "This post began in a Note on AI-generated images from , following on from a post about plagiarism in Substack Notes. That earlier conversation was relatively clear. Copying someone else’s words and presenting them as your own is plagiarism. The harm is direct. The boundary is visible.Images complicate this clarity.In this post we will:Surface why AI generated images are often framed as theft, even when they are not copies.Share perspectives from writers and artists with different stakes in the issue.Hold space for disagreement without forcing resolution.Slow AI is a shared space for reflection. All posts are free, but if you wish to support the work, you can choose a paid subscription.Why AI generated images feel different from textWhen people accuse AI generated images of being theft, they are often responding to three things at once.First, training data. Many image models were trained on copyrighted work without consent. That is not speculation. It is documented. This is a corporate decision, not an individual one, but it shapes how every output is received.Second, visibility. Images carry immediate aesthetic impact. A single image can do the work of many paragraphs. When an AI generated image replaces commissioned or credited art, the loss feels concrete.Third, opacity. With text, influence has always been messy. Writers absorb voices, rhythms, and forms. With images, the lack of visible sources makes influence harder to judge. Without provenance, people assume the worst.This combination explains the heat of the debate, even when the specific accusation does not hold.When AI starts to sound like youWriting with AI can quietly flatten your voice and shift decisions you did not mean to hand over. Keep Your Voice is a Slow AI guide that shows how to stay present, deliberate, and in control when using AI tools to write.Download herePerspectives from the communityMy position, briefly, is that AI generated images are not theft in the same way as copying and passing off someone else’s work. Most outputs are novel combinations rather than replicas. That places them closer to uncredited influence than plagiarism. The problem is that we cannot see the sources. Without transparency, ethical judgement becomes guesswork. I would like platforms to show training sources or at least categories. Right now, we are arguing in the dark. However, my main income is not as an artist. If it were, I would probably weigh risk and harm differently.I don’t experience most AI-generated images as theft so much as turbocharged influence, and those aren’t the same moral category. Theft to me is the deliberate copy-pasting of an actual artifact (or its core concept) and pretending it came from your hands. I love to always give this example when the topic comes up - art history is basically one long chain of visible “stealing”. Classical music too. It’s full of composers building whole works as variations of someone else’s theme where the transformation IS the actual point (Bach’s Passacaglia in C minor was directly inspired by Buxtehude’s version). AI models learn from existing work (just like every human artist), but the main question is, can we meaningfully regulate the difference between influence and theft? I don’t think we can, and until we do, my bias is super simple. Be honest about when AI helps and accept that pure originality is always a more comforting myth that we use to feel safe.I don’t think novel combinations are theft. Targeted replication? That’s a different animal.Look, I use AI art tools constantly. My whole ToxSec aesthetic, the rust, the slime, the skull-at-the-terminal energy, took real iteration to dial in. When I see my work, I don’t feel like I stole from anyone. Same way comic artists didn’t steal from whoever drew the first panel. We absorb what we love, remix it, make something that feels like ours.But here’s the line for me: if I scraped someone’s entire portfolio, trained a model on it, and started pumping out their exact vibe under my name? That’s theft. The pixels don’t have to be identical. What matters is I’m extracting the novel combination they built. The brand, the aesthetic fingerprint, the thing that makes their work recognizable as theirs. That’s what we actually own in creative work. Not individual images. The accumulated choices that become a signature.The real problem isn’t the technology. We’re asking individual creators to police something that should be a platform-level responsibility. Most of us just want to make things. We shouldn’t need law degrees to figure out if we crossed a line. I don’t see AI-generated images as outright theft, even though they are undeniably trained on artists’ styles and techniques without consent, which is ethically uncomfortable. When someone uses prompts to create an image for something like a Substack article, the finished result is a unique combination of specific instructions and mixed influences, not a copied Monet or Van Gogh passed off as original work, for arguments sake. Artists have always learned from, absorbed, and echoed other artists, and unless you are explicitly asking an AI to replicate a named artist’s style, what you are doing is closer to imitation and synthesis than plagiarism.I don’t see AI-generated images as theft, but two things bother me. First, when people persistently replicate someone else’s distinctive style without adding their own spirit - it’s not illegal, just hollow. Second, and this one’s personal: when I generate an image but haven’t put my own interpretation into it. If I’m just typing “inspiring entrepreneur at desk” and accepting whatever appears, I’ve created noise, not communication. The tool amplifies intent. If your intent is clear and specific, you get something useful. If it’s just “I need an image here,” you get generic filler that wastes everyone’s time. I’d rather focus on making sure what I create actually adds something worth reading.“Good artists copy, great artists steal.” Picasso said that a century before AI. What he meant with this: real innovation comes from gathering ideas everywhere, running them through your own creative chemistry set, and making something unmistakably yours and not copying something and hoping no one notices.My Substack is visually driven, and AI is part of my creative toolkit. The way I work follows the same logic designers use when they build mood boards. Influence is how visual languages evolve. The line sits somewhere else. Borrowing a vibe is normal. Borrowing someone’s face, voice, or recognisable signature without consent is misappropriation with faster rendering. Think of the difference between Taylor Swift being pulled into a political campaign via AI images she never endorsed, versus Jennifer Lopez partnering on JenAI for Virgin Voyages was licensed, compensated and fully consensual. AI didn’t break the old rules of art; it just lit them up in neon so we finally have to look.Shaming people who use AI tools is not helpful. Any shaming should be aimed at the AI companies who steal copyrighted images without getting consent or giving credit or compensation (the 3Cs of creative rights, as CIPRI calls them). On the other hand, I also don’t think it’s ok to just say “Oh well, too bad that artists’ works and livelihoods have been stolen” and merrily go along using AI tools built on exploiting their works.We all deserve to have ethical AI tools to choose from. But with few exceptions, AI companies are only going to offer us ethical tools if we, the users and consumers, compel them to build ethical tools. I agree fully with other commenters on transparency. We don’t all have to agree on whether we are ok with AI-generated imagery. But people who care strongly one way or another deserve to know. And more people being up-front about using AI should help to mitigate the un-helpful shaming. I spent a lot of time creating digital art by hand during the pandemic, and I even fine-tuned a Stable Diffusion model to imitate my style. (It didn’t work, the outputs were mediocre and quickly drifted back to the model’s core training data.) Real art is real work, and I can sympathize with artists who are losing jobs to generative AI. I think AI companies did steal their creations.And yet, I’m also using generative AI to create consistent branding for my newsletter, which I see as “content” not “art.” (My use of AI is displacing free Canva, not trained artists.) And AI is so deeply enmeshed with modern creator tools that it’s getting increasingly difficult to draw the line between “AI-assisted” and “100% human.”I hold contradictory views on this. I suspect a lot of people do.What we are learning from this discussionA few shared principles are emerging.Blame travels upward more effectively than sideways.Transparency builds trust even when disagreement remains.Context matters more than slogans.Ethical use is a practice, not a label.For images, as for text, the question is less is this allowed and more what kind of space are we trying to build together.Why this mattersSlow AI is about deliberate practice. AI generated images sit at a fault line between creativity and extraction. How we talk about them shapes norms long before policy catches up.If we default to accusation, people hide. If we default to indifference, harm normalises.A slower conversation leaves room for responsibility without collapse into purity tests.If you have thoughts, experience, or disagreement, please add it below the line. There are no final answers here, only an opportunity to learn together.We read and respond to all your comments.Go slow.",
  "harvested_at": "2026-01-28T22:49:08.363514"
}